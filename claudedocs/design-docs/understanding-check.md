# Understanding Check

## Overview

Understanding Check は、AI が生成した成果物（コード、Design Doc、FeatureSpec、調査レポート）に対するエンジニアの「理解したつもり」を、承認前に検証する仕組みである。エンジニアが主要な判断を自分の言葉で説明し、AI がドラフト時に記録した rationale との比較を通じてギャップを発見する。受動的な承認を、説明可能な理解に基づく承認に変えることが目的である。

## Context and Scope

### 問題の背景

AI がコードや設計文書を書く現在の開発ワークフローでは、成果物の品質が高いほどエンジニアは内容を「理解したつもり」で承認しやすい。チームメンバーから「なぜこの設計にしたの？」と問われて初めて、自分が説明できないことに気づく。これは認知心理学で「説明の深さの錯覚」(Illusion of Explanatory Depth — Rozenblit & Keil, 2002) として知られる現象であり、人が複雑なシステムへの理解を系統的に過大評価し、説明を求められて初めてギャップに気づく認知バイアスである。

AI 生成コードの高い表面的整合性（文法的に正しく、一貫したスタイル、詳細なコメント）は、この錯覚を増幅する可能性がある。なお、AI コンテキストでの IOED（以下、この略称を使用）に関する正式な学術研究は現時点で存在せず、この増幅仮説は未検証である。逆に、AI 生成コードの一貫した構造とコメントが真の理解を容易にし、IOED がむしろ軽減される可能性もある。Understanding Check はいずれの場合も、エンジニアに説明を求めることで理解の状態を表面化させる。

### 理論的基盤

Understanding Check は3つの確立された学習メカニズムに基づく：

- **生成効果 (Generation Effect)**: 情報を受動的に読むより、自分で言語化（生成）する方が長期記憶に定着しやすい (Slamecka & Graf, 1978)。AI の説明を読むのではなく、まず自分で説明することで理解が深まる
- **自己説明効果 (Self-Explanation Effect)**: 自己説明プロンプトを伴う学習は、プロンプトなしの学習に比べ新規問題への転移率が2倍以上向上する。「なぜ？」「どのように？」という推論型の質問が最も効果的である (Chi et al., 1989, 1994)
- **間隔効果 (Spacing Effect)**: 間隔を空けた復習は直後の復習より長期記憶への定着率が約23%向上する (Cepeda et al., 2006 メタ分析)。別セッションでの実行はこの効果を自然に活用する

### 既存メカニズムとの差分

claude-praxis には既に理解を促す仕組みがある：

| メカニズム | 提供するもの | Understanding Check との違い |
|-----------|------------|---------------------------|
| `check-past-learnings` | 過去の判断の rationale を提示し「同じ前提が成り立つか？」を問う | 過去の判断の想起。現在の判断の説明能力は検証しない |
| decision points | 実装中に複数の選択肢を提示しエンジニアに選択させる | 選択の機会。選んだ理由を後から説明できるかは検証しない |
| `/compound` | 実装後の学びを振り返り蓄積する | 振り返りの促進。理解の穴の事前発見ではない |

Understanding Check はこの残存ギャップ — 「選んだけど説明できない」「承認したけど理解していない」状態 — を対象とする。

## Goals / Non-Goals

### Goals

- 全ワークフロー（`/feature-spec`, `/design`, `/implement`, `/debug`）のドラフト完了後に opt-in で実行される理解度チェックを提供する
- 「エンジニアが先に説明 → AI の事前記録済み rationale と比較」の生成ベース学習構造で理解ギャップを表面化する
- 発見されたギャップを progress.md に記録し、`/compound` で学びとして蓄積する導線を作る
- 完了レポートに理解確認ステータスを記載し、可視性を持たせる（「主要判断5件中3件を説明可能」等）
- 別セッションからの単体実行（`/understanding-check`）で間隔効果を活用可能にする

### Non-Goals

- 理解度のスコアリングや長期履歴管理システム — 完了レポートへの記載と progress.md への記録で代替する
- 強制的なゲート（blocking hook 等）— opt-in であり、compliance theater を避ける設計とする
- AI による回答の正誤判定 — AI は「判定者」ではなく「自身の rationale の開示者」として位置づける

## Proposal

3つの設計判断を中心に構成する。

### Design Decision 1: Explain-Compare-Discover

Understanding Check の核は「先に説明、後から比較」の3段構造である。

**なぜこの順序か**: 生成効果の研究は、AI の rationale を先に見せると「アンカリング」（先行情報に引きずられて自分の判断が歪む現象）が発生し、自己生成の学習効果が失われることを示す。エンジニアが AI の説明を読んでから自分で言い直しても、それは「生成」ではなく「再生」であり、理解の検証にならない。

**なぜ対比的フィードバックか**: AI がエンジニアの回答を「正解」「不正解」と判定する評価的フィードバック (evaluative feedback) には2つの問題がある。第一に、LLM は人間の回答に同意する傾向（sycophancy）があり、判定の信頼性が低い。第二に、Kluger & DeNisi (1996) の Feedback Intervention Theory によれば、評価的フィードバックは次の説明の生成性を減少させる。対比的フィードバック (contrastive feedback) — AI は自身の rationale を開示し差分を構造化して提示する — は、sycophancy リスクを低減しつつ、エンジニアが自分でギャップを認識する学習効果を維持する。

**対比的フィードバックの限界と対策**: 対比的フィードバックは sycophancy を完全に排除するものではない。AI がどの差分を強調しどう表現するかは一種の判断であり、差分を軽視する表現（「概ねよく捉えていますが、一点補足すると...」）は sycophancy の別形態になり得る。また、エンジニアの説明と AI の rationale が部分的に重なるケース（同じ結論だが異なる推論経路、意味的に同等だが構造的に異なる説明、一部正確で一部不正確）では、単純な「触れた/触れていない」の二値では表現できない。これらの対策として、比較ステップでは構造化された出力フォーマットを使用する：

| 判断 | あなたの説明 | AI の rationale | 差分 |
|------|------------|---------------|------|
| [判断1] | [要約] | [要約] | [欠落/相違/一致] |

この構造化により、AI の裁量的な表現を制約し、差分の軽視を防ぐ。Skill の実装で `receiving-code-review` の anti-sycophancy パターン（欠落している観点の明示的指摘、表面的な一致に基づく肯定の禁止）を適用する。

**AI の rationale が間違っている場合**: 差分は必ずしも「エンジニアの理解不足」を意味しない。AI の判断が不適切であった場合、差分は「AI の推論の限界」を示す。Understanding Check はこの区別を明示的に扱い、いずれの場合もギャップとして `/compound` に流す。「ドメインについての学び」と「AI の判断をいつ疑うべきかの学び」の両方が蓄積される。

### Design Decision 2: 事前記録された Rationale

Understanding Check の質は、比較対象となる rationale の質に依存する。ドラフト完了後に AI に「なぜこう設計したか」を再構成させると、エンジニアの回答がコンテキストに含まれるため、アンカリング汚染が発生する。AI の rationale がエンジニアの回答に無意識に引きずられ、差分が過小評価される。

**解決策**: 各コマンドは、主要な判断を行った時点で rationale を progress.md に構造化して記録する。Understanding Check はこの事前記録済み rationale を取得して比較に使用する。rationale の生成と比較は時間的に分離されるため、アンカリング汚染が構造的に排除される。

この設計は同時に3つの問題を解決する：

1. **Sycophancy 回避**: rationale はエンジニアの回答を見る前に凍結されている
2. **別セッションでの文脈復元**: rationale がファイルに記録されているため、新しいセッションでも完全に復元可能
3. **質問の質の向上**: progress.md の Decision/Rationale フォーマットに、却下した選択肢と判断の根拠が含まれることで、表面的な質問ではなく推論型の質問が生成可能になる

なぜテンプレートではなくデータ依存か: 過去の学びから、テンプレートの空欄埋め（形式的な遵守行為 — compliance handshake と呼ばれるパターン）ではなく、上流ステップの出力データを下流の必須入力にする因果的依存構造が有効であることが確認されている。progress.md に主要判断が記録されていなければ、Understanding Check は有意義な質問を生成できない。

**正直な制約**: ただし、この因果的依存は Scout → Plan の依存（Plan が Scout findings の引用を要求する）ほど強くない。Understanding Check は素材不足時に「スキップ」するため、記録が不十分でも下流に影響が出ない。つまり、記録品質への「構造的圧力」は実際には弱い。記録品質は不均一になることを前提として設計する。対策として、質問生成は素材の充実度に応じて適応する：

- **rationale が豊富な場合**（却下した選択肢、トレードオフ分析を含む）: 「なぜ X ではなく Y を選んだか？」という代替案に踏み込む質問
- **rationale が薄い場合**（Decision/Rationale のみ）: 「この判断の背景にある制約は何か？」という判断の文脈を問う質問
- **rationale が不十分な場合**: 質問数を減らすか、スキップする。劣化した質問の無理な生成は形骸化を招く

### Design Decision 3: Dual-Mode Execution

Understanding Check は2つの実行モードを提供する。

**Workflow Proposal Mode（同一セッション）**: 各ワークフローのドラフト完了後に「理解度チェックしますか？」と提案される。コンテキストが豊かで質問の文脈が自然に理解できるが、間隔効果は得られない。また、ワークフローによってコンテキストウィンドウの余裕が異なる：

| ワークフロー | 同一セッション実行の適性 | 理由 |
|------------|----------------------|------|
| `/feature-spec` | 高い | 比較的短いワークフロー、コンテキスト圧迫が少ない |
| `/design` | 中程度 | research + review で消費するが、判断材料が豊富 |
| `/implement` | 低い | 最長のワークフロー、Final Review 後にコンテキストが最も圧迫 |
| `/debug` | 中程度 | 調査範囲による |

**Standalone Mode（別セッション）**: `/understanding-check` コマンドとして単体実行する。progress.md + 成果物（+ git diff）から文脈を復元し、事前記録された rationale を取得して質問を生成する。コンテキストウィンドウの制約がなく、間隔を空けることで短期記憶ではなく定着した理解を検証できる。ただし、文脈復元の質は progress.md の記録の充実度に依存する。

**間隔効果の適用範囲について**: 間隔効果の研究（Cepeda et al., 2006）は長期記憶の保持を対象としており、Understanding Check の目的（現在の理解の検証）とは厳密には異なる。既に深く理解しているエンジニアには間隔を空けた検証がデシラブルな困難（Bjork, 1994）として機能するが、そもそも深く処理していないエンジニア（Understanding Check の主要ターゲット）には、間隔が検索不能な困難になる可能性がある。Standalone Mode の主な利点はコンテキストウィンドウの解放であり、間隔効果は副次的な利点として位置づける。

**なぜ2つのモードが必要か**: 同一セッションのみだとコンテキスト圧迫で `/implement` 後の実行が困難になり、別セッションのみだとワークフローからの提案がないため adoption が低下する。Stop hook の提案は同一セッション実行を促すのではなく、Standalone の存在をリマインドする役割を担う：「`/understanding-check` で理解度チェックが可能です」。推奨は Standalone だが、ワークフロー内でのリマインドがなければ Standalone の存在自体が忘れられる。

### Question Design

質問は以下の原則に従う：

- **「なぜ」と「どのように」に集中する**: Chi et al. (1994) の研究は、推論型質問（「なぜこのアーキテクチャ？」「なぜ代替案を却下した？」）が定義型質問（「XXX とは何？」）や事実型質問（「何を変更した？」）より2倍以上の知識転移を生むことを示す
- **3〜5問**: 研究に基づく最適範囲。少なすぎると検証が不十分、多すぎると疲労が生じ説明の質が低下する
- **事前記録された rationale から生成**: テンプレートからではなく、実際の判断記録から質問を導出する。却下された選択肢がある判断は特に質問の素材として価値が高い
- **質問選択の基準**: 質問対象の選択自体が一種の判断行為である（全判断の中からどの3〜5件を選ぶかが結果を左右する）。選択基準を明示する：(1) 代替案が却下された判断を優先（「なぜ X ではなく Y か」が最も深い理解を問う）、(2) エンジニアが decision point で直接関与した判断は優先度を下げる（関与した判断は既に理解している可能性が高い）、(3) 複数のワークフローステップにまたがる判断を優先（影響範囲が広い）
- **ワークフローごとの素材の違いを考慮する**: `/design` は Design Doc 自体が豊富な素材を持つ（Alternatives Considered、設計判断）。`/implement` は progress.md エントリとコード差分が主な素材であり、質問の深さが制約される。素材が不十分な場合は質問数を減らし、無理に生成しない

### Integration Points

**完了レポート**: Understanding Check を実行した場合のみ、ステータスフィールドを表示する（「Understanding Check: 主要判断5件中3件を説明可能、2件にギャップ発見」等）。未実施の場合はフィールド自体を省略する。常に「未実施」を表示する設計は、opt-in の理念に反する受動的な社会的圧力（guilt mechanism）を生むため採用しない。ステータスフィールドは `rules/verification.md` の完了レポートテンプレートにオプショナルフィールドとして追加する。

**Stop hook advisory**: 既存の stop-verification-gate に Understanding Check のリマインドを追加する。ワークフロー完了後に「`/understanding-check` で理解度チェックが可能です」と通知する。同一セッションでの実行を提案するのではなく、Standalone コマンドの存在をリマインドする。compound advisory と同様の非ブロッキング方式。

**既存コマンドとの統合方式**: 既存コマンド（`/implement`, `/design`, `/feature-spec`, `/debug`）は Understanding Check スキルを直接呼び出さない。統合は stop hook のリマインドのみを経由する。これにより、既存コマンドのフェーズ構造を変更せず、Understanding Check を「ワークフロー外の独立した活動」として位置づける。直接統合を避ける理由は、ワークフロー完了時点での decision fatigue（長いワークフローの末尾で追加の判断を求めるとほぼ確実にスキップされる）を回避するためである。

**/compound 統合**: Understanding Check で発見されたギャップは progress.md に「Gap: [topic] — [説明できなかった内容]。Rationale: [AI の事前記録済み rationale]」形式で記録される。`/compound` がこれを learnings ファイルに昇格させることで、次回以降の判断の糧になる。

## Alternatives Considered

### Standalone-Only Model

`/understanding-check` コマンドのみ提供し、ワークフローへの統合は行わない。

**利点**: 実装がシンプル（コマンド1つ追加のみ、既存コマンドの変更不要）。常に別セッションで実行されるため間隔効果が最大化される。

**Proposal が優れている理由**: ワークフローからの提案がなければ、エンジニアがコマンドの存在を認識し、自発的に実行する動機が弱い。過去の学びから、テキストだけの opt-in は機械的な可視性メカニズムなしでは使われなくなることが確認されている。完了レポートのステータスフィールドと stop hook の提案は、Standalone-Only モデルでは機能しない。

**再検討すべき状況**: 全ワークフローでのコンテキスト圧迫が深刻で、同一セッション内での提案自体がコンテキストバジェットの浪費になる場合。または、エンジニアが定期的に `/understanding-check` を自発的に実行する習慣が確立された場合。

### Hook-Enforced Model

Stop hook で Understanding Check 未実施を blocking し、実行を事実上強制する。

**利点**: adoption が最大化される。スキップが不可能なため、理解度チェックが確実に実行される。

**Proposal が優れている理由**: 学習は自発的な取り組みから価値が生まれる。強制されたチェックは「テストに通る」最適化を引き起こし、compliance theater のリスクが高い。エンジニアはもっともらしい説明を生成して「合格」することに注力し、本来の目的である理解の深化が損なわれる。また、小さなバグ修正や設定変更など、チェックの価値が薄い作業にも一律に適用されるため、ワークフロー全体の摩擦が増大する。

**再検討すべき状況**: セキュリティやアーキテクチャなど、特定の高リスクドメインに限定して強制する選択肢は将来の検討に値する。全面的な強制ではなく、ドメインベースの選択的強制。

### Evaluative Feedback Model（正誤判定）

AI がエンジニアの回答を「正解」「不正解」と判定し、スコアを提示する。

**利点**: 明確なフィードバック。エンジニアは自分の理解度を数値で把握できる。

**Proposal が優れている理由**: LLM の sycophancy 傾向により判定の信頼性が低い。エンジニアの回答を安易に「正解」と判定すると、理解の illusion を強化してしまう。また、Kluger & DeNisi (1996) によれば、評価的フィードバックは次の生成的行動（説明の試行）を抑制する。対比的フィードバックは sycophancy を構造的に回避しつつ、学習効果を維持する上位互換である。

**再検討すべき状況**: LLM の評価能力が大幅に向上し、sycophancy が信頼できるレベルで解決された場合。または、チーム全体での理解度の定量的な比較が必要になった場合（ただし Non-Goals の範囲）。

### Teaching Mode（ワークフロー内 Socratic Method）

ドラフト完了後ではなく、ワークフローの各判断時点で AI がステップごとに推論を説明し、エンジニアに予測や評価を求める。

**利点**: 誤解をリアルタイムで発見でき、成果物完成後に振り返る必要がない。

**Proposal が優れている理由**: ワークフロー全体を大幅に遅延させる。経験豊富なエンジニアにとっては既知の判断も多く、全ステップでの対話は煩わしい。また、ワークフロー中のインタラクションはコンテキストウィンドウを大量に消費し、成果物の品質に影響する。Understanding Check はワークフロー完了後に集約された形で実行するため、ワークフローの効率を維持しつつ理解の検証を実現する。

**再検討すべき状況**: 特定のドメイン（セキュリティ設計、新技術の初回導入等）で、判断時点での理解確認がリアルタイムで必要な場合。ワークフロー全体ではなく、特定の高リスク判断に限定した Teaching Mode は検討に値する。

## Cross-Cutting Concerns

### Sycophancy Mitigation

AI が Understanding Check で sycophancy を示すと、理解の錯覚を強化するという逆効果を生む。3層の防御で対応する：

1. **構造的制約**: 比較ステップで構造化された出力フォーマット（判断・説明・rationale・差分のテーブル）を使用し、AI の裁量的な表現を制約する。これにより差分の軽視（「概ねよく捉えていますが...」）を防ぐ。ただし、質問の選択やフレーミング自体が判断行為であることは認識した上で、選択基準を明示することで裁量を制約する（Question Design 参照）
2. **時間的分離**: rationale はドラフト時に事前記録されており、エンジニアの回答の影響を受けない。アンカリング汚染（先行情報によって後続の判断が歪む現象がデータ汚染として作用すること）が構造的に排除される
3. **パターン適用**: `receiving-code-review` skill の anti-sycophancy パターンを適用する。欠落している観点を明示的に指摘し、表面的な一致に基づく肯定を避ける

### Context Window Management

Understanding Check の実行タイミングはコンテキストウィンドウが最も圧迫された瞬間（ワークフロー完了後）である。対策：

- **質問数の上限**: 3〜5問に制限し、コンテキスト消費を最小化
- **Standalone 推奨**: 特に `/implement` 後は別セッションでの実行を推奨。コンテキスト制約なし + 間隔効果の二重の利点
- **素材不足時のスキップ**: progress.md の記録が不十分で有意義な質問を生成できない場合は、劣化した質問を無理に生成するのではなく「十分な素材がないためスキップします」と明示する

### Layer Architecture Placement

Understanding Check は claude-praxis の7層アーキテクチャにおいて複数の層にまたがる：

| 層 | 配置 | 役割 |
|---|------|------|
| **Command** | `commands/understanding-check.md` | Standalone 実行時のフェーズ順序と PAUSE ポイント |
| **Skill** | `skills/understanding-check/SKILL.md` | Explain-Compare-Discover の手順、質問生成ロジック、ギャップ記録フォーマット |
| **Hook** | `stop-verification-gate.ts` への追加 | ワークフロー完了後の非ブロッキング提案 |
| **Rule** | `rules/verification.md` への追加 | 完了レポートの Understanding Status フィールド |

Skill がコアの手順を所有し、Command が Standalone 実行のフェーズを定義し、Hook が可視性を提供する。既存コマンド（`/implement` 等）はスキルを直接呼び出すか、stop hook の提案を通じて間接的に利用する。

### Stop Hook Interaction

既存の stop-verification-gate は以下の順序でチェックを実行する：

1. Verification gate（blocking — typecheck/lint/test 未実施の警告）
2. Implement final-review gate（blocking — final review 未実施の警告）
3. Compound advisory（non-blocking — progress.md の未昇格エントリの提案）

Understanding Check のリマインドは compound advisory と同じ非ブロッキング層に追加する。現在の stop hook 実装は最初のアドバイザリーマッチ後に終了するため、Understanding Check リマインドと compound advisory は同一 stop イベントで同時に表示されない（相互排他）。Understanding Check リマインドを compound advisory の前に配置することで、理解度チェック → 学びの蓄積の自然な順序を維持する。

### Upstream Recording Burden

Understanding Check の質は、コマンドが実行中に progress.md へ記録する主要判断の質に依存する。各コマンドへの影響：

| コマンド | 現在の記録 | 変更点 | 判断素材の充実度 |
|---------|----------|--------|----------------|
| `/design` | 完了時に1エントリ | Alternatives Considered の各判断を記録 | 高い — Design Doc 自体が豊富な素材 |
| `/implement` | タスク完了ごとに1エントリ | decision point での記録を追加 | 中程度 — progress.md + コード差分 |
| `/feature-spec` | 完了時に1エントリ | スコープ判断を記録 | 中程度 — FeatureSpec の In/Out Scope |
| `/debug` | 完了時に1エントリ | 仮説の採用/棄却を記録 | 高い — 調査レポートの仮説と証拠 |

既存の Decision/Rationale/Domain フォーマットは変更しない。頻度の増加のみ。記録はコマンドの自然なフロー（design の Alternatives Considered、implement の decision points）に組み込み、新たな記録ステップは追加しない。

### Backward Compatibility

Understanding Check は opt-in 機能だが、インフラストラクチャの一部は全ユーザーに影響する。各変更の影響範囲を明示する：

| 変更 | 影響範囲 | UC 未使用時の影響 |
|------|---------|-----------------|
| 完了レポートのステータスフィールド | UC 実行時のみ表示 | なし — フィールド自体が省略される |
| Stop hook のリマインド | 全ユーザー | 1行の非ブロッキング通知が追加される。compound advisory と同等の影響 |
| progress.md の記録頻度増加 | 全コマンド | UC の有無にかかわらず判断の記録が充実する。これは UC のためだけではなく、`/compound` や `check-past-learnings` の品質向上にも寄与する独立した改善 |

progress.md の記録頻度増加は、Understanding Check がなくても価値がある変更として位置づける。`/compound` が学びを蓄積し `check-past-learnings` が想起する際、判断の rationale が豊富であるほど品質が向上する。Understanding Check はこの改善の最も明確な消費者だが、唯一の消費者ではない。

## Concerns

| リスク | 深刻度 | 緩和策 | 残存リスク |
|-------|--------|--------|-----------|
| 常にスキップされる（新規性効果の減衰含む） | High | Stop hook リマインド、/compound 導線、実行時の完了レポート記載。ただし強制なし | High — opt-in の本質的限界。初月以降の利用率低下は予測される。価値を体験したエンジニアのみが継続する前提で設計 |
| 質問の質が低い | Medium | 素材充実度に応じた適応的質問生成（豊富→代替案質問、薄い→文脈質問、不十分→スキップ） | Medium — upstream 記録品質への構造的圧力は弱い。記録品質の不均一を前提とした設計 |
| 対比的フィードバックでの sycophancy | Medium | 構造化出力フォーマット、質問選択基準の明示、anti-sycophancy パターン適用 | Medium — 完全排除は不可能。選択的強調の sycophancy は構造化で制約するが、残存する |
| AI rationale が間違っている | Medium | 差分は「理解不足」と「AI の限界」の両方を含むことを明示。両方を /compound に流す | Low — 設計で対応済み |
| IOED 増幅仮説が未検証 | Low | Understanding Check 自体が経験的な検証手段。/compound の蓄積で傾向を観察可能。逆仮説（AI が IOED を軽減）の可能性も認識 | Low — いずれの場合も生成効果の学習メリットは残る |
| ワークフロー全体の累積的重量 | Medium | Understanding Check はワークフロー外の独立活動として位置づけ。コマンドのフェーズに組み込まない。Stop hook は1行のリマインドのみ | Low — decision fatigue は stop hook のリマインド方式で回避 |

## Review Checklist

- [ ] Architecture approved — layer placement (skill/command/hook/rule) が7層モデルに準拠
- [ ] User experience impact reviewed — opt-in フロー、質問数、フィードバック形式がエンジニアの体験を損なわない
- [ ] Integration points verified — progress.md、完了レポート、stop hook、/compound との統合が既存システムと整合
- [ ] Sycophancy mitigation assessed — 3層防御（構造的回避・時間的分離・パターン適用）の妥当性
