# Competing Strategy Exploration

## Overview

claude-praxisのAI支援開発ワークフローにおいて、プランニングの品質がその後の全工程を決定するにもかかわらず、現行ワークフローでは単一の戦略方向性で設計・計画を進めるため、複数の妥当なアプローチが存在する場合でも最初に識別された候補が暗黙的に採用される傾向がある。本設計は、設計文書作成（`/design`）と実装計画作成（`/implement`）の計画段階で、2-3の根本的に異なる戦略方向性を並列で評価し、構造化比較を経て最良を選定するオプトインプロトコルを定義する。

## Context and Scope

### 現行の問題

`/design`のPhase 1（Plan and Research）は複数のresearcherを並列ディスパッチし、合成ルールに従い「2-3の候補アプローチとトレードオフ」を識別する。しかし、識別された候補の各々を独立に評価するステップは存在しない。合成は1回のみであり、候補の列挙後にそのままPhase 2（アウトライン作成）に進む。結果として、controllerが合成時に「最も自然」と感じた候補が暗黙的に採用されやすい。

`/implement`のPhase 1（Planning）も同様である。scoutの探索結果に基づいてプランを作成するが、複数の実装戦略を明示的に比較する仕組みはない。

プランは下流の全工程（設計→実装→コード）を決定する。プランニング段階で最適な方向性を選定することが、最もレバレッジの高い品質改善ポイントである。

### 着想元と既存パターン

本設計はCodebuff（オープンソースのAIコーディングエージェント）の並列マルチ戦略パターンに着想を得ているが、Codebuffの「競合実装」（複数のimplementerが同一タスクにコードを書いてselectorが選定）とは本質的に異なる。Codebuffのパターンはコード実装レベルの競合であり、コストが15x+に達する。本設計は戦略・リサーチレベルの競合であり、コードは一切書かない。

claude-praxisの既存スキルでは、`agent-team-execution`の「Competing Hypothesis Debugging」（複数の仮説を並列で検証し、生存した仮説を採用）が最も近いパターンである。本設計はこの仮説検証パターンを設計・計画段階に応用したものと位置づけられる。

### 背景概念

本設計で使用する概念を先に定義する。

**planner** — `workflow-planner`スキルを指す。タスク分析、エージェント選定、実行計画の生成を担い、戦略探索の発動判断を行う。

**controller** — `/design`または`/implement`のメインオーケストレーションセッション（main Claude）を指す。plannerの判断に基づいてエージェントをディスパッチし、結果を合成する。

**候補アプローチと戦略方向性** — Phase 1の合成が識別する「候補アプローチ」は浅い列挙（名前とトレードオフの概要）である。本提案の「戦略方向性」（以下「方向性」）は、候補アプローチを出発点に制約ベース分岐によって構造化されたものであり、独立した評価を伴う。

**LLM収束問題** — 同一のLLMに「根本的に異なるアプローチを生成せよ」と指示しても、出力が表面的な差異にとどまる傾向。temperatureの調整（T=0.8-1.2以上）では多様性がプラトーに達し、深い構造的差異は生まれない。これは出力のデコーディングではなく、学習された分布自体の制約に起因する。

**制約ベース分岐** — LLM収束問題を回避するために、各方向性に異なる制約セット（最適化目標、前提条件、依存関係の選択）を明示的に割り当てる手法。「異なる解を考えよ」という曖昧な指示ではなく、「レイテンシを最小化し、メモリ使用量2倍を許容する解」と「メモリを最小化し、レイテンシ10倍を許容する解」のように、構造的に異なる解空間を探索させる。

**LLM-as-judge** — LLMに複数の選択肢を評価・ランキングさせる手法。位置バイアス（先に提示された選択肢を好む）、冗長性バイアス（長い出力を高評価する）、自己選好バイアス（自身の出力を好む）などの既知の問題があり、設計判断のような正解が一意でない比較では信頼性が低い。

## Goals / Non-Goals

### Goals

- `/design`と`/implement`の計画フェーズに統合可能な、戦略方向性の並列評価プロトコルを定義する
- LLM収束問題を構造的に緩和する方向性生成メカニズムを設計する
- 評価結果の比較・選定において、LLM-as-judgeのバイアスを回避する仕組みを設計する

### Non-Goals

- **競合実装**（コードレベルの競合）— `enhanced-multi-agent-coordination.md`で既に却下済み。本設計はコードを一切書かず、戦略の妥当性評価のみを行う
- **FeatureSpec/Debugへの適用** — FeatureSpecは「何を作るか」を定義する段階であり、戦略方向性を競わせる対象がない。Debugは既存の`agent-team-execution`（Competing Hypothesis Debugging）でカバーされている
- **全ワークフローへのデフォルト適用** — 明確な最善策がある場合、探索のコストは品質向上に見合わない。plannerが条件を満たす場合にのみ提案するオプトインとする

## Proposal

### Design Decision 1: 探索は「戦略スケッチ」であり「深い調査」ではない

戦略探索の目的は、各方向性の完全な調査ではなく、方向性の妥当性評価である。選定された方向性に対しては、既存のPhase 1研究フェーズ（4-5 researchers、7-10xコスト）が深い調査を実行する。

この判断には3つの理由がある。

1. **2レベルネスト制約との整合性**: Claude Codeの2レベルネスト制約により、strategy-researcher（level 2）はsub-agentをディスパッチできない。「戦略スケッチ」（方向性の妥当性・主要リスク・実現可能性の評価）はhaiku researcherの単一コンテキスト内で完結する作業であり、この制約と自然に整合する
2. **explore-then-exploitパターン**: 全方向性を深く調査するのではなく、広く浅い探索（explore）で有望な方向性を特定し、選定後に深い調査（exploit）を行う。これは探索コストを最小化しつつ、最終的な調査深度を維持するパターンである
3. **コスト管理**: 各方向性にフルresearcherチーム（4-5名）を配置すると、N方向 × M researcher = 12-15 researchersとなり、20-30xのコストに達する。「戦略スケッチ」は1 researcher/directionで完結し、コストを4-7xに抑える

**深度の限界と認識**: 戦略スケッチは方向性の「明らかな非妥当性」を検出するフィルターであり、「妥当性の保証」ではない。スケッチで妥当と評価された方向性が、深掘り後に実現不可能と判明するリスクは残る。このリスクに対しては、フォールバックプロトコルで対応する（後述のConcerns「戦略スケッチの深度不足」を参照）。戦略探索の価値は「確実に正しい方向を選ぶ」ことではなく、「明らかに不適切な方向を除外し、有望な方向に調査リソースを集中する」ことにある。

再検討条件：トークンコストが大幅に低下し、全方向性への深い調査のコストが許容範囲に入った場合、「戦略スケッチ」の制約を緩和して各方向にフルチームを配置する設計を再検討する。

### Design Decision 2: 方向性生成には制約軸による構造的分岐を使用する

LLM収束問題を緩和するために、方向性の生成を「異なるアプローチを考えよ」という自由形式ではなく、事前定義された制約軸に基づく構造的分岐として設計する。

**制約軸の選定手順**: 制約軸は汎用テンプレートから選ぶのではなく、Phase 1の研究合成で識別された設計上の緊張（design tensions）から導出する。合成が「候補Aは高速だが複雑」「候補Bはシンプルだが拡張性に制約」と識別した場合、「速度 vs シンプルさ」と「拡張性 vs 制約の受容」が制約軸になる。この導出方法により、問題領域に無関係な軸（例：認証設計の問題に「sync vs async」を適用する）を選定するリスクを軽減する。

汎用テンプレート（導出の出発点として参照可能）：

| 軸カテゴリ | 例 |
|---|---|
| 最適化目標 | レイテンシ vs メモリ vs 開発速度 vs 保守性 |
| アーキテクチャ仮定 | モノリス vs マイクロサービス、同期 vs 非同期 |
| 依存関係の選択 | 自作 vs ライブラリ、クラウドサービス vs セルフホスト |
| 信頼モデル | ゼロトラスト vs ネットワーク境界 |
| データモデル | 正規化 vs 非正規化、RDB vs ドキュメントDB |

**最低分岐条件**: 生成された方向性は、制約軸のうち少なくとも2つで異なる必要がある。1つの軸でしか異ならない方向性は「変種」であり「根本的に異なる方向性」ではない。controllerが方向性生成後にこの条件を検証し、不十分な場合は制約を変更して再生成するか、探索自体を取りやめる。

この判断の根拠は、research知見に基づく。temperatureによる表面的多様性は実効性が低いが、制約セットによる構造的分岐は異なる解空間の探索を強制する。制約軸を研究合成の設計緊張から導出することで、問題領域の実際のトレードオフに基づいた分岐を生成する。

再検討条件：LLMの生成多様性が構造的に改善され（モデルアーキテクチャの変更等）、制約ベース分岐なしでも十分な方向性の独立性が達成できる場合、制約軸メカニズムを簡略化する。

### Design Decision 3: 選定にはLLM-as-judgeではなく事前定義基準 + 人間判断を使用する

複数の戦略方向性を比較する際、LLM-as-judgeではなく、事前定義された評価基準マトリクスと人間の最終判断を組み合わせる。

この判断の根拠は3つある。

1. **LLM-as-judgeの既知バイアス**: 位置バイアス、冗長性バイアス、自己選好バイアスは実証されており、設計判断のような正解が一意でない比較では信頼性が低い
2. **構造化出力による選択的省略の防止**: 過去の学びから、構造化フォーマット（テーブル、固定セクション）は全項目の明示を強制し、都合の悪い評価の暗黙スキップを防ぐ。各セルに信頼度（high/medium/low）を付与することで、浅い評価に過度の信頼が付与されるリスクを緩和する
3. **偽信頼の緩和**: 構造化比較テーブル自体が「リサーチが浅いにもかかわらず高い信頼感を与える」リスクがある。これを緩和するため、比較結果に対して1名のDevil's Advocateをディスパッチし、方向性間の真の差異、評価基準の適切性、比較に含まれない有望な方向性の存在を検証する

再検討条件：LLM-as-judgeの信頼性が大幅に改善され（位置バイアスの解消等）、人間の判断を介さずに信頼性の高い戦略選定が可能になった場合。

### Strategy Exploration Protocol

以下のプロトコルは、plannerが戦略探索の発動を判断した後に実行する。

**Step 1: 発動条件の評価**

plannerが以下の全条件を満たすと判断した場合に発動する。

- 初期研究（既存Phase 1の合成）が2つ以上の妥当な候補アプローチを識別している
- 候補間の最適解が自明ではない（明確な優位性を持つ候補がない）
- 候補が異なるトレードオフを持つ（単なる実装詳細の違いではなく、設計判断レベルの違い）

条件を満たさない場合（候補が1つ、または1つが明確に優位）、探索は発動せず、現行ワークフローをそのまま継続する。

**Step 2: 方向性生成（controllerが実行）**

controllerが2-3の戦略ブリーフを生成する。各ブリーフは以下を含む。

- 方向性の名前と1文要約
- 割り当てられた制約セット（制約軸による構造的分岐）
- 最適化目標（この方向性が何を優先するか）
- 主要な仮定（この方向性が成立する前提条件）

生成後、分岐検証を実施する。方向性間で少なくとも2つの制約軸が異なることを確認する。不十分な場合は制約を変更して再生成するか、探索を取りやめる。

**Step 3: 並列評価（haiku researcher per direction）**

各方向性に1名のhaiku researcherをディスパッチする（最大3名が並列実行）。各researcherは割り当てられた制約セットの下で以下を評価する。

- **妥当性**: この方向性は技術的に実現可能か？既知の障害はあるか？
- **主要リスク**: この方向性の最大のリスクは何か？（技術的・運用的・コスト的）
- **実現コスト**: 実装の複雑さと必要工数の概算
- **トレードオフ**: この方向性が犠牲にするものは何か？

各researcherの出力は「戦略スケッチ」であり、完全な調査ではない。深い調査は選定後のフェーズで実施する。

**Step 4: 比較の構造検証**

方向性別の評価完了後、1名のDevil's Advocateをディスパッチし、比較の構造的妥当性を検証する。DAの役割は方向性間の「品質判断」（どちらが良いか）ではなく、「構造検証」（比較自体が成立しているか）に限定する。品質判断はLLM-as-judgeと同じバイアスリスクを持つため、人間に委ねる。

DAの検証項目（構造検証のみ）：

- 方向性間の差異は表面的か、それとも構造的か？（制約軸の差異が実際のアーキテクチャの差異を生んでいるか）
- 比較テーブルの全セルが埋まっているか？信頼度は各スケッチの深度と整合しているか？
- 比較に含まれていない、研究合成で言及された方向性が存在しないか？

**Step 5: 構造化比較と人間選定**

controllerが全評価結果を構造化比較テーブルにまとめる。

| 評価基準 | 方向性A | 方向性B | 方向性C | 信頼度 |
|---|---|---|---|---|
| 技術的妥当性 | [評価] | [評価] | [評価] | [high/medium/low] |
| 主要リスク | [評価] | [評価] | [評価] | [high/medium/low] |
| 実現コスト | [評価] | [評価] | [評価] | [high/medium/low] |
| トレードオフ | [評価] | [評価] | [評価] | [high/medium/low] |

DAの所見を比較テーブルの後に添付する。

人間に提示し、人間が方向性を選定する。controllerは推奨を示してもよいが、最終判断は人間が行う。

**Step 6: 選定後の深掘り**

選定された方向性に対して、既存の研究フェーズ（Phase 1の残り、または`/implement`のscout dispatch）を実行する。この段階で初めてフルresearcherチームが投入される。

### `/design`への統合

Phase 1（Plan and Research）の合成ステップ後、Phase 2（アウトライン作成）前に挿入する。

この位置を選んだ理由は2つある。第一に、合成が候補アプローチを識別した後が、方向性生成のための情報が揃う最も早いタイミングである。第二に、Phase 2でアウトラインを作成する際には方向性が確定している必要があり、アウトライン作成前に完了する必要がある。

統合後のフロー：

1. Phase 1前半：researcher dispatch → 合成（2-3候補識別）— 既存通り
2. **Strategy Exploration**（新規）：方向性生成 → 並列評価 → 比較DA → 人間選定
3. Phase 1後半：選定された方向性に対して追加研究（必要な場合）
4. Phase 2：選定された方向性でアウトライン作成 — 既存通り

plannerは合成結果を見て、探索の発動条件を評価する。条件を満たさない場合は、既存フローをそのまま継続する。

### `/implement`への統合

Phase 1 Step 1（Gather Context）後、Step 2（Create Plan）前に挿入する。

この位置を選んだ理由：コンテキスト収集（scout dispatch + learnings check）の完了後が、複数の実装戦略の全体像が見えるタイミングである。プラン確定前に比較を完了する必要がある。

統合後のフロー：

1. Step 1：Design Doc読み込み + scout dispatch + learnings check — 既存通り
2. **Strategy Exploration**（新規）：実装戦略の方向性生成 → 並列評価 → 比較DA → 人間選定
3. Step 2：選定された戦略でプラン作成 — 既存通り

実装レベルでの制約軸の例：テスト戦略（統合テスト重視 vs ユニットテスト重視）、リファクタリング範囲（最小変更 vs 周辺コードの改善含む）、依存管理（既存ライブラリ活用 vs 新規導入）。

### コスト分析

コストは単一サブエージェント呼び出しを1xとして表記する（`agent-team-execution`と同じ基準）。

| 項目 | トークンコスト |
|---|---|
| 方向性生成 + 分岐検証（controller） | ~1-1.5x |
| 並列評価（haiku researcher × 2-3） | 4-6x |
| 比較構造検証（DA 1名） | 1-2x |
| 構造化比較の合成（controller） | ~0.5x |
| **合計（探索フェーズのみ）** | **7-10x** |

既存のPhase 1研究（4-5 researchers）は選定後の方向性に対してのみ実行されるため、全体のコスト増は探索フェーズの7-10x分である。戦略探索を使用しない場合の全体コスト（Phase 1: 7-10x + Phase 2以降）に対して、探索フェーズが追加される。

競合実装パターン（15x+ × N方向）との比較では、「戦略スケッチ」は実装を含まないため、1方向あたりのコストが大幅に低い。ただし、探索フェーズと選定後の研究フェーズを合算すると、全体としてはPhase 1の2倍程度のコストになる（7-10x探索 + 7-10x深掘り = 14-20x vs 通常の7-10x）。

**コスト正当化の前提**: この追加コストは、誤った方向性の選定が下流全体のやり直しを引き起こすリスクがある場合に正当化される。ただし、現行ワークフローで方向性選定が不適切だった頻度のベースラインデータは存在しない。本提案の価値は「方向性の再選定コスト（全フェーズのやり直し）」と「探索の追加コスト（7-10x）」の比較に依存するが、前者の発生頻度は実測されていない。この不確実性を踏まえ、本提案はオプトインとし、導入後に実測データを収集する（後述の「導入後の計測指標」を参照）。

## Alternatives Considered

### Approach B: コントローラ内比較（追加ディスパッチなし）

controllerが戦略ブリーフを生成し、controller自身が各ブリーフを評価・比較する。追加のresearcherディスパッチは行わない。

本提案より優れる点：追加トークンコストがゼロ。ワークフローへの変更が最小限。

本提案を選んだ理由：独立した検証ソースの原則に違反する。controllerが自身の生成物を評価するため、確証バイアスのリスクが高い。過去の学びから、エージェント特化は独立した検証ソースがある場合にのみ有効であり、controller自身による自己評価はこの条件を満たさない。

再検討条件：確証バイアスを構造的に防止する自己評価手法（例：自己反駁を強制するプロンプト技法）の有効性が実証された場合。

### Approach C: 新規 competing-strategies スキル

戦略探索プロトコルを独立したスキルとして分離し、`/design`と`/implement`のコマンドがそのスキルを呼び出す。

本提案より優れる点：関心の分離が明確。スキルの責務が「戦略探索」として独立し、テスト・改善が容易。

本提案を選んだ理由：workflow-plannerの既存ステップモデル（Step 4: Generate Execution Plan）に統合する方が自然であり、新しいスキルを導入するとplannerおよび`agent-team-execution`との責務の重複が生じる。過去の学びから、3箇所以上の手続き重複が確認された場合にスキル抽出を検討するのが適切であり、現時点では`/design`と`/implement`の2箇所のみ。

再検討条件：戦略探索が`/debug`や`/feature-spec`を含む3つ以上のコマンドで使用されるようになり、共有スキル化の閾値（3箇所以上の重複）に達した場合。

### 全方向性にフルresearcherチームを配置

各方向性にoss-research + best-practices + counter-researchのフルresearcherチームを配置し、深い独立調査を実施する。

本提案より優れる点：各方向性の評価が深く、戦略スケッチでは見落とされるリスクを発見できる可能性がある。

本提案を選んだ理由：N方向 × M researcher = 9-15 researchers（20-30xのトークンコスト）となり、コストが過大。「戦略スケッチ + 選定後深掘り」のexplore-then-exploitパターンの方がコスト効率が高い。全方向性を深く調査しても、最終的に選定されるのは1方向のみであり、選定されなかった方向性への投資は回収されない。

再検討条件：トークンコストが大幅に低下し、フルチーム × N方向のコストが戦略探索なしの場合と同等になった場合。

### 比較にDevil's Advocateを配置しない（方向性ごとにDAを配置）

各方向性にDevil's Advocateを1名ずつ配置し（合計2-3名のDA）、方向性内のリスクを深く検証する。比較全体に対するDAは配置しない。

本提案より優れる点：各方向性のリスクがより深く検証される。

本提案を選んだ理由：方向性ごとのDAは方向性内のリスクを検証するが、方向性間の比較の妥当性（差異の真偽、基準の適切性、欠落した方向性の存在）を検証しない。構造化比較の「偽信頼」リスクは比較全体に対する検証でしか緩和できない。また、方向性ごとにDAを配置するとコストが2-3倍増加する。

再検討条件：戦略スケッチの深度を増す必要があり、各方向性のリスク検証を強化する価値がコスト増を上回る場合。

## Cross-Cutting Concerns

### コスト管理

戦略探索は追加7-10xのトークンコストを伴う。コストを制御するために以下の措置を設ける。

- 発動はplannerの判断 + 人間の承認によるオプトイン
- 方向性の数は最大3（分析麻痺の研究知見に基づく上限）
- 戦略スケッチ（浅い評価）で深い調査のコストを回避
- plannerが発動を提案する際、推定コスト増を明示

### 2レベルネスト制約との整合性

Claude Codeの2レベルネスト制約（サブエージェントがさらにサブエージェントを起動できない制約）との整合性は構造的に確保されている。strategy-researcherはcontrollerから直接ディスパッチされるlevel 2エージェントであり、sub-agentを使用しない。「戦略スケッチ」という設計判断（Design Decision 1）がこの制約と自然に整合する — 各researcherは単一コンテキスト内で方向性の妥当性評価を完結させる。

### 既存ワークフローへの影響

本提案はオプトインであり、既存ワークフローを変更しない。発動条件を満たさない場合、`/design`と`/implement`は現行通り動作する。発動条件を満たす場合でも、人間が承認しなければ探索は実行されない。

### コンテキスト圧縮時の永続化

戦略比較結果はprogress.md（Flow file）に記録する。選定理由はDesign Doc（`/design`の場合）またはプラン（`/implement`の場合）に組み込まれるため、比較結果自体の長期永続化は不要である。コンテキスト圧縮でprogress.mdが剪定されても、選定結果はDesign Doc/プランに残る。

## Concerns

### 制約ベース分岐の実効性

制約軸を与えても、LLMが各制約下で実質的に異なる結論に到達するとは限らない。特に、制約軸の選定が問題領域に対して不適切な場合、分岐が形式的なものにとどまるリスクがある。

緩和策：方向性生成後に分岐検証を実施する。最低分岐条件（2つ以上の制約軸で異なる）を満たさない場合、制約を変更して再生成するか、探索自体を取りやめる。plannerのドメインコンテキストに制約軸の例示を含め、問題領域に適した軸の選定を支援する。

### 構造化比較の偽信頼

構造化比較テーブルが、浅い戦略スケッチに基づく評価に過度の信頼を付与するリスクがある。テーブル形式は主観的判断にも「リサーチに基づく客観的評価」の印象を与えることが行動経済学の研究で示されている。

緩和策：比較Devil's Advocateが比較自体の妥当性を検証する。各セルに信頼度（high/medium/low）を付与し、浅い評価と深い評価を区別可能にする。テーブルの冒頭に「戦略スケッチに基づく概算評価であり、選定後の深掘りで結論が変わる可能性がある」旨を明示する。

### 方向性生成の品質

plannerが「根本的に異なる」方向性を生成できるかは、制約軸の選定品質に依存する。問題領域によっては、2つの制約軸で異なっていても、実質的に同じアーキテクチャに収束する場合がある（例：「同期/非同期」と「モノリス/マイクロサービス」で異なっていても、両方ともRESTful APIになる）。

緩和策：分岐検証において、制約軸の差異だけでなく、結果として生じるアーキテクチャの構造的差異も確認する。過去の設計で使用された効果的な制約軸の組み合わせをlearningsとして蓄積し、方向性生成の品質を漸進的に改善する。

### 戦略スケッチの深度不足

haiku researcherによる戦略スケッチでは、深い技術的リスクや実装上の落とし穴を見落とす可能性がある。戦略スケッチの段階で「妥当」と評価された方向性が、深掘り後に実現不可能と判明するリスクがある。

緩和策：戦略スケッチの目的を「明らかな非妥当性の検出」に限定し、「妥当性の保証」を期待しないことを明示する。選定後のPhase 1深掘りが技術検証を担う。深掘りで重大な問題が発見された場合のフォールバックプロトコル：

1. controllerが次点の方向性を特定する（比較テーブルから）
2. 次点の方向性に対して深掘り研究を実施する（追加7-10x）
3. フォールバックは最大1回とする。2回目のフォールバックが必要な場合、戦略探索の方向性生成自体に問題があるため、探索結果を破棄し、controllerが通常の合成フローで方向性を判断する

フォールバック発生時の最大コスト：7-10x（探索） + 7-10x（最初の深掘り、破棄） + 7-10x（フォールバック深掘り） = 21-30x。このコストはフォールバック発生時のみであり、発生率が高い場合は戦略スケッチの深度自体を再検討すべきシグナルとなる。

### 発動判断のメタ意思決定問題

戦略探索の発動が有益かどうかを判断するためには、問題の不確実性の度合いを事前に評価する必要がある。しかし、不確実性が高いからこそ探索が必要であり、不確実性の評価自体が不確実であるという循環がある。

緩和策：plannerの発動判断を「条件ベース」（候補が2つ以上、明確な優位性がない）とすることで、メタ判断の負荷を軽減する。最終的な発動承認は人間が行うため、plannerの誤判断は人間が補正できる。

## 導入後の計測指標

本設計は理論的分析に基づいており、戦略探索が実際にどの程度の品質向上をもたらすかの実測データは存在しない。導入後、以下のメトリクスを計測して設計判断を検証すべきである。

- **発動率**: `/design`および`/implement`の呼び出しのうち、戦略探索が発動した割合。発動条件の妥当性を検証する
- **方向性維持率**: 探索で選定された方向性が、深掘り後も維持された割合。フォールバック頻度が高い場合、スケッチ深度の再検討が必要
- **トークンコスト増（予測 vs 実測）**: 7-10xの予測に対する実測値
- **方向性変更率の比較**: 戦略探索あり/なしで、実装フェーズ中に方向性を変更した割合の比較。現行ワークフローのベースラインがないため、探索なしの場合も追跡する
- **分岐検証の棄却率**: 方向性生成後の分岐検証で不十分と判定され、再生成または探索取りやめになった割合。棄却率が高い場合、制約軸選定手順の改善が必要

## Review Checklist

- [ ] Architecture approved — workflow-planner統合とagent-team-execution既存パターンとの整合
- [ ] Feasibility confirmed — 2レベルネスト制約下での戦略スケッチの実現可能性
- [ ] Cost/benefit justified — 7-10x追加コストに見合う品質向上の論拠
- [ ] Migration plan — 既存ワークフローへの影響なし（opt-in）の確認
- [ ] Risk mitigations adequate — LLM収束、偽信頼、深度不足、メタ意思決定への対応
